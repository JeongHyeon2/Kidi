Kidi: 단안 카메라 비전 기반 차량 주행 정보 추정 시스템
딥러닝 비전 기술을 활용하여 단안 카메라(블랙박스) 영상만으로 차량의 주행 속도와 조향 방향을 추정하는 시스템

1. 프로젝트 개요
Kidi는 GPS, IMU, CAN bus 데이터 등 별도의 센서 없이, 오직 전방을 주시하는 단안 카메라 영상만을 입력으로 받아 차량의 핵심 주행 정보인 속도와 조향 상태를 실시간으로 추정하는 것을 목표로 합니다.

본 프로젝트는 보험개발원의 과제로, 수집된 주행 데이터를 기반으로 운전자 습관 분석(UBI), 사고 상황 재구성, 위험 운전 감지 등 다양한 보험 상품 및 서비스 개발에 활용될 수 있는 핵심 기술을 개발합니다.

2. 핵심 기술 및 시스템 파이프라인
본 시스템은 여러 컴퓨터 비전 모델이 유기적으로 결합된 파이프라인 구조로 동작합니다.


① Optical Flow Estimation (움직임 추정)
연속된 두 프레임 사이에서 픽셀 단위의 움직임 벡터를 계산합니다. 이는 장면 전체의 겉보기 움직임(Apparent Motion)을 포착하는 단계입니다.

사용 모델: **RAFT (Recurrent All-Pairs Field Transforms)**와 같은 최신 옵티컬 플로우 모델을 사용하여 정확하고 밀도 높은 모션 필드를 생성합니다.

② Monocular Depth Estimation (깊이 추정)
단안 영상의 한계인 깊이 정보 부재를 극복하기 위해, 딥러닝 모델로 각 픽셀의 깊이(카메라로부터의 거리)를 추정합니다.

가까운 물체와 먼 물체의 움직임 차이를 해석하는 데 필수적인 정보를 제공합니다.

③ Dynamic Object Masking (동적 객체 분리)
순수한 '내 차의 움직임'을 분석하기 위해, 독립적으로 움직이는 다른 차량이나 보행자 등을 탐지하고 마스킹(계산에서 제외)합니다.

사용 모델: RT-DETR과 같은 실시간 객체 탐지 모델을 활용합니다.

④ Ego-Motion Solver (자차 움직임 해석)
본 시스템의 핵심으로, 앞선 단계에서 얻은 옵티컬 플로우(2D), 깊이(3D), 그리고 카메라 내부 파라미터를 종합하여 **'카메라의 3D 공간상 움직임'**을 역산합니다.

움직임 관계식(Motion Field Equation)을 기반으로 최소제곱법(Least-Squares) 또는 RANSAC과 같은 기법을 적용하여 카메라의 이동 벡터 T (Tx, Ty, Tz)와 회전 벡터 Ω (ωx, ωy, ωz)를 계산합니다.

⑤ 주행 정보 변환 및 정제 (Speed & Steering Estimation)
계산된 카메라의 움직임 벡터를 실제 차량의 주행 정보로 변환합니다.

속도 (km/h): 주로 전진 방향 이동량인 Tz 값을 기반으로 계산합니다.

조향 방향: 수직축 중심의 회전량인 ωy (Yaw) 값을 통해 좌/우 회전 상태를 추정합니다.
